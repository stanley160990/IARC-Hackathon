{"cells":[{"cell_type":"markdown","metadata":{"id":"6h2qWn0CVBsv"},"source":["&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&ensp;\n","[Home Page](../Start_Here.ipynb)\n","\n","\n","[Previous Notebook](The_Problem_Statement.ipynb)\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","[1](The_Problem_Statement.ipynb)\n","[2]\n","[3](Manipulation_of_Image_Data_and_Category_Determination_using_Text_Data.ipynb)\n","[4](Countering_Data_Imbalance.ipynb)\n","[5](Competition.ipynb)\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","[Next Notebook](Manipulation_of_Image_Data_and_Category_Determination_using_Text_Data.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"XUQedKPsVBs5"},"source":["# Estimasi Intensitas Siklon Tropis Menggunakan Deep Convolutional Neural Network - Bagian 2 \n","\n","**Daftar Isi:**\n","\n","- [Pendekatan Masalah](#Pendekatan-Masalah)\n","- [Data](#Data)\n","- [Tasks](#Task)\n","- [Model and Loss](#Model-and-Loss) \n","- [Training and Evaluation](#Training-and-Evaluation) \n","- [Bekerja dengan Image Dataset](#Bekerja-dengan-Image-Dataset)\n","- [Bekerja dengan Text Dataset](#Bekerja-dengan-Text-Data)\n","\n","\n","**Setelah menyelesaikan notebook ini diharapkan peserta dapat:**\n","\n","- Memahami Dataset\n","- Mempelajari tahapan Pre-processing dari Dataset"]},{"cell_type":"markdown","metadata":{"id":"Z9WDIAYKVBs6"},"source":["# Pendekatan Masalah\n","\n","Selama lab ini, akan digunakan list terminologi berikut untuk membantu memahami bagaimana proyek Machine Learning harus direncanakan dan dijalankan:\n","\n","1. **Data**: Untuk memulai proyek ML apa pun, kami memerlukan data yang telah diproses sebelumnya dan dapat dimasukkan ke dalam jaringan.\n","2. **Task**: Terdapat banyak tugas yang ada di ML, kita perlu memastikan kita memahami dan mendefinisikan pernyataan masalah secara akurat.\n","3. **Model**: Kita perlu membangun model yang tidak terlalu dalam atau kompleks, sehingga membutuhkan banyak daya komputasi atau terlalu kecil sehingga tidak dapat mempelajari fitur-fitur penting.\n","4. **Loss**: Dari sekian banyak _loss functions_ yang hadir, kita perlu hati-hati memilih _loss function_ yang cocok untuk tugas yang akan kita laksanakan.\n","5. **Learning**: Seperti yang telah di sebutkan pada notebook sebelumnya, ada berbagai _optimiser_ masing-masing dengan kelebihan dan kekurangannya. Jadi di sini kita memilih _optimiser_ yang cocok untuk tugas kita dan melatih model kita menggunakan hyperparameter yang ditetapkan.\n","6. **Evaluation**: Ini adalah langkah penting dalam proses untuk menentukan apakah model kita telah mempelajari fitur-fiturnya dengan benar dengan menganalisis bagaimana kinerjanya ketika data yang tidak terlihat diberikan kepadanya."]},{"cell_type":"markdown","metadata":{"id":"8pwaiuVBVBs8"},"source":["## Data\n","\n","##### Data Image akan diberi anotasi menggunakan Data Text untuk membuat himpunan data kita dari mana model akan belajar mengklasifikasikan jenis siklon. \n","\n","\n","**Optional** : [Downloading Dataset](Downloading_Images.ipynb)\n","\n","Dataset telah diunduh untuk peserta, dan kemudian akan digunakan.\n","\n","Contoh gambar yang akan dimasukkan ke dalam model: \n","\n","<table><tr>\n","<td><img src=\"images/example.jpg\" alt=\"Drawing\" style=\"width: 320px;\"/></td>\n","<td><img src=\"images/example1.jpg\" alt=\"Drawing\" style=\"width: 320px;\"/></td>\n","</tr>\n","</table>\n","\n","*Sumber: https://www.nrlmry.navy.mil/*\n","\n","#### Setiap Gambar akan diberi anotasi ke kategori Intensitas Siklon menggunakan data teks dengan bantuan tabel berikut:\n","\n","![alt text](images/cat.png)"]},{"cell_type":"markdown","metadata":{"id":"AoZVhmjDVBs-"},"source":["## Task \n","\n","Ada berbagai tugas yang ada di DL, dan tugas yang akan kita lakukan disebut Klasifikasi Multi-class.\n","\n","Di sini, beberapa kelas hadir, dan model perlu mengklasifikasikan gambar ke dalam kelas yang benar. \n","\n","Kelas berikut adalah intensitas siklon tropis yang akan diperkirakan menggunakan kecepatan angin siklon tersebut: \n","- NC ( No Category         , $\\leq 20$ knots)\n","- TD ( Tropical Depression , $20-33$ knots)\n","- TS ( Topical Storm       , $34-63$ knots)\n","- H1 ( Category One        , $64-82$ knots)\n","- H2 ( Category Two        , $83-95$ knots)\n","- H3 ( Category Three      , $96-112$ knots)\n","- H4 ( Category Four       , $113-136$ knots)\n","- H5 ( Category Five       , $\\geq 137$ knots)\n","\n","##### Contoh dari Klasifikasi Multi-Class: \n","<img src=\"images/multi_class1.png\" alt=\"Drawing\" style=\"width: 520px;\"/></td>\n"]},{"cell_type":"markdown","metadata":{"id":"i5jgyHoSVBs_"},"source":["## Model and Loss \n","\n","#### Kami akan menggunakan model yang diberikan dalam makalah penelitian: \n","\n","Hyper-parameter dalam model ini ( ukuran kernel, jumlah lapisan tersembunyi ) dibuat khusus untuk proyek ini. \n","\n","![alt text](images/model.png)\n","\n","\n","### Loss Function:\n","\n","Kami telah melihat tentang tiga fungsi kerugian Multi-Class yang berbeda, yaitu:\n","- *Multi-Class Cross-Entropy Loss*\n","- Sparse Multi-class Cross-Entropy Loss\n","- Kullback Leibler Divergence Loss\n","\n","Kita akan menggunakan loss function Multi-Class Cross-Entropy Loss untuk klasifikasi ini. Dan seseorang dapat menggunakan salah satu dari tiga fungsi kerugian untuk tugas ini.\n","\n","##### Multi-Class Cross-Entropy loss: \n","\n","Sebelum kita memahami bagaimana nilai kerugian dihitung, mari kita pahami bagaimana output diproduksi.\n","\n","Ketika kita melatih model kita, kita mengonversi semua kategori menjadi array 1 dan 0. Mari kita asumsikan bahwa kita memiliki model untuk memprediksi apakah gambar yang diberikan adalah kucing atau anjing, kemudian kita mulai melabeli semua output dalam himpunan data kita dan menetapkan 'kucing = [ 1 , 0 ]' dan 'anjing = [ 0 , 1 ] ' dan kemudian kita akan melatih model berdasarkan itu, model tersebut kemudian akan memprediksi probabilitas output dari apa yang dipikirkannya, katakanlah kita memberinya gambar kucing, sehingga kita mendapatkan output menjadi '[ 0,87 , 0,13]' yang menyiratkan bahwa model tersebut 87% yakin bahwa itu adalah kucing, tetapi ini masih belum cukup baik kita kemudian menghitung kesalahan dalam kasus ini dengan persamaan berikut. \n","\n","$$ Loss = J(w) = - \\frac{1}{N}\\sum_{n=0}^{N} \\left[ y_n \\log{\\hat{y_n}} + (1 - y_n) \\log{(1-\\hat{y_n})}  \\right] $$\n","\n","Jadi, jika kita mencoba menghitung kerugian dalam kasus kita dari persamaan, kita akan mencoba menghitung nilai kerugian untuk nilai yang berbeda. \n","\n","$ Loss = - \\frac{1}{2}\\left[ \\log{0.87} + (1 - 0) \\log{(1 - 0.13)} \\right] = -1 * \\log{0.87} = 0.060 $\n","\n","Jika model kita dilatih dari waktu ke waktu dan jika outputnya adalah '[ 0,90 , 0,10 ]' , maka mari kita hitung kerugian.\n","\n","$ Loss = - \\frac{1}{2}\\left[ \\log{0.90} + (1 - 0) \\log{(1 - 0.10)} \\right] = -1 * \\log{0.90} = 0.045 $\n","\n","Jadi, sekarang kami melihat nilai kerugian kami telah berkurang, jadi menggunakan persamaan ini, model kami belajar untuk memahami bagaimana kinerjanya dan memperbarui bobot untuk berkinerja lebih baik. \n","\n","### Optimizer: \n","\n","Dalam model ini, kita akan menggunakan SGD Optimizer (Stochastic Gradient Decent) Optimizer.\n","\n","##### Penurunan Gradien: \n","\n","Penurunan gradien adalah algoritma optimasi yang digunakan untuk meminimalkan beberapa fungsi dengan bergerak secara iteratif ke arah penurunan paling curam seperti yang didefinisikan oleh negatif dari gradien. \n","\n","Mari kita dapatkan wawasan untuk memahami cara kerja penurunan gradien:\n","\n","Mulai dari puncak gunung, kami mengambil langkah pertama menuruni bukit ke arah yang ditentukan oleh gradien negatif. Selanjutnya, kami menghitung ulang gradien negatif (melewati koordinat titik baru kami) dan mengambil langkah lain ke arah yang ditentukannya. Kami melanjutkan proses ini secara berulang sampai kami sampai ke bagian bawah grafik kami, atau ke titik di mana kami tidak bisa lagi bergerak menuruni bukitâ€“minimum lokal.\n","\n","<td><img src=\"images/grad.jpg\" alt=\"Drawing\" style=\"width: 420px;\"/></td>\n","\n","*Sumber: https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931*\n","\n","GD berjalan melalui semua sampel dalam set pelatihan untuk melakukan satu pembaruan untuk parameter dalam iterasi tertentu. Di SGD, di sisi lain, Anda hanya menggunakan satu atau subset sampel pelatihan dari set pelatihan Anda untuk melakukan pembaruan untuk parameter dalam iterasi tertentu. \n","\n","Menggunakan SGD akan lebih cepat karena hanya satu sampel pelatihan yang digunakan dan mulai meningkatkan dirinya sendiri segera dari sampel pertama.\n","\n","\n","## Training and Evaluation \n","\n","Kami akan membagi himpunan data kami menjadi tiga set berbeda:\n","\n","- Training Set\n","    - 72 % of the Dataset\n","- Test Set \n","    - 18 % of the Dataset\n","- Validation Set \n","    - 10% of the Dataset \n","\n","Anda bebas bermain-main dengan rasio ini di notebook berikutnya."]},{"cell_type":"markdown","metadata":{"id":"uxR0WrZLVBtB"},"source":["Ringkasan pendekatan:\n","\n","![alt_text](images/now.png)\n"]},{"cell_type":"markdown","metadata":{"id":"BnodYs4lVBtC"},"source":["# Bekerja dengan Image Dataset \n","\n","Gambar diunduh di folder 'Dataset'\n","\n","### Untuk bekerja dengan gambar, kita perlu memahami hierarki Gambar Tersimpan: \n","\n","Hierarki Himpunan Data ini mirip dengan Basis Data Angkatan Laut AS untuk menyimpan gambar, dan ini telah dipertahankan untuk menyimpan gambar agar dapat dengan mudah menskalakan / menambahkan lebih banyak fitur ke dalamnya.\n","\n","Sekarang mari kita pahami bagaimana pengaturannya:\n"]},{"cell_type":"raw","metadata":{"id":"hgUqVLmLVBtD"},"source":["Dataset                                  --> Root Folder\n","â””â”€â”€ tcdat                                --> SubFolder Pertama ( tcdat = tropical cyclone database )\n","    â”œâ”€â”€ tc04                             --> SubFolder Kedua ( tcxx = xx stand for yeah 20xx , tc04 = 2004) \n","    â”‚   â””â”€â”€ ATL                          --> SubFolder Ketiga ( ATL -> Singkatan dari Atlantic Cyclones )\n","    â”‚       â”œâ”€â”€ 01L.ALEX                 --> SubFolder Keempat ( Nama Siklon )\n","    â”‚       â”‚   â””â”€â”€ ir                   --> SubFolder Kelima ( Jenis Gambar, Kami hanya akan bekerja dengan IR )\n","    â”‚       â”‚       â””â”€â”€ geo              --> SubFolder Keenam \n","    â”‚       â”‚           â””â”€â”€ 1km          --> SubFolder Ketujuh ( Rentang Gambar ) \n","                                         --> Gambar akan dimuat di sini\n","                                      \n","Jadi, Sekarang kita perlu memastikan kita dapat mengulangi melalui ini:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nepFWC5uVBtF"},"outputs":[],"source":["# Import Library yang diperlukan \n","import os\n","\n","# List apa yang ada di direktori 'Dataset/'\n","dir ='Dataset/'\n","a = os.listdir(dir)\n","try :\n","    a.remove('Aug') # Mengecualikan gambar yang ditambah\n","except : \n","    pass\n","# Rekursi untuk menemukan jumlah total Gambar  \n","total=[]\n","\n","# SubFolder Pertama\n","for i in a:\n","    b = os.listdir(dir+i)\n","    # SubFolder Kedua\n","    for j in b :\n","        c = os.listdir(dir+i+'/'+j)\n","        # SubFolder Ketiga\n","        for k in c :\n","            d = os.listdir(dir+i+'/'+j+'/'+k)\n","            # SubFolder Keempat ( Nama Siklon )\n","            for l in d :\n","                # 5th , 6th dan 7th selalu '/ir/geo/1km', jadi tambahkan ke string.\n","                e = os.listdir(dir+i+'/'+j+'/'+k+'/'+l+'/ir/geo/1km')\n","                print(j+'-> '+l+' --> '+ str(len(e)))\n","                # e berisi daftar gambar siklon itu\n","                total = total + (e)\n","print('')\n","print('Jumlah total gambar yang ada di Himpunan Data :',len(total)) "]},{"cell_type":"markdown","metadata":{"id":"RkvLIuezVBtI"},"source":["Jadi, sekarang mari kita coba memahami bagaimana gambar itu terlihat. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"221_nmAkVBtJ"},"outputs":[],"source":["total.sort()\n","total[:5]"]},{"cell_type":"markdown","metadata":{"id":"nGC2WtK9VBtJ"},"source":["Sekilas, kita dapat memahami Image Name memiliki banyak informasi yang tersimpan di dalamnya. \n","\n","Sekarang, mari kita pahami format Data yang disimpan: \n","\n","*YYYYMMDD.HHMM*. Nama Satelit yang menangkap gambar dan Data lain yang relevan.jpg\n","\n","YYYYMMDD.HHMM  -> Year Month Date. Hours Minutes \n","\n","*Sekarang kita akan menggunakan waktu tanggal yang disediakan dalam nama gambar untuk membubuhi keterangan jenis kategori menggunakan data text*"]},{"cell_type":"markdown","metadata":{"id":"xN_HdAJ3VBtK"},"source":["# Bekerja dengan Text Data \n","\n","Kami akan menggunakan Best Track Data (HURDAT2) di Wilayah Atlantik untuk Siklon Tropis. Dari [description](http://www.nhc.noaa.gov/data/#hurdat) di halaman web data NOAA:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WxsZ3drQVBtK"},"source":["<p class=\"reg\"><span style=\"font-weight:bold;\">Database Atlantic hurricane (HURDAT2) 1851-2018</span> <br>\n","Himpunan data ini disediakan pada 10 Mei 2019 untuk menyertakan pembaruan 2018 ke trek terbaik.\n","</p>\n","\n","<p class=\"reg\">\n","Dataset ini (<a href=\"/data/hurdat/hurdat2-format-atlantic.pdf\">dikenal sebagai Atlantic HURDAT2</a>) memiliki\n","format teks yang dibatasi koma dengan informasi enam jam di lokasi,\n","angin maksimum, tekanan pusat, dan (mulai tahun 2004) ukuran semua siklon tropis dan siklon subtropis yang diketahui.\n","Database HURDAT asli telah dihentikan.</p>\n","\n","**( Optional - [Pre-processing the Data](Pre-Processing_Text_Data.ipynb) )**\n","\n","Data ini mengikuti format CSV yang Dimodifikasi karena Pandas ( Python Library for Data Manipulation and Analysis ) tidak bisa mendapatkan data yang dapat digunakan secara langsung. Oleh karena itu, kami akan membangun parser kami untuk melakukan pra-proses data ini dan membuatnya dapat digunakan dalam tugas-tugas mendatang.\n","\n","Langkah-langkah yang diikuti pada Notebook [Pre-Processing Text Data](Pre-Processing_Text_Data.ipynb) antara lain:\n","\n","- Memahami format data \n","- Menyimpan siklon dalam Dictionary\n","- Mengubah Dictionary menjadi sebuah Dataframe\n","- Merestrukturisasi kolom dan membuatnya dapat dibaca\n","- Mengganti nilai sentinel dan menghapus string kosong\n","- Menghapus ruang yang tidak diinginkan dan mengindeks ulang Dataframe\n","- Menyimpan Dataframe menjadi sebuah File CSV"]},{"cell_type":"markdown","metadata":{"id":"j4N2TdlOVBtL"},"source":["## Mari kita lihat data text:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_kJ-TmuVBtL"},"outputs":[],"source":["import pandas as pd\n","atlantic_storms= pd.read_csv('atlantic.csv')\n","atlantic_storms.tail(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAmuU6R6VBtM"},"outputs":[],"source":["# Kita akan menggunakan Tanggal dan Waktu untuk Mengetahui Kecepatan Topan \n","# Kita akan membuatnya menjadi format yang dapat dibaca\n","\n","atlantic_storms['date'] = pd.to_datetime(atlantic_storms['date'].astype(str))\n","atlantic_storms['date'] = atlantic_storms.apply(lambda srs: srs['date'].replace(hour=int((\"%04d\" % srs['hours_minutes'])[:2]), minute=int((\"%04d\" % srs['hours_minutes'])[2:])), axis='columns')\n","del atlantic_storms['hours_minutes']\n","atlantic_storms.tail()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dsd-0SCfVBtM"},"outputs":[],"source":["# Sekarang mari kita simpan Data Text untuk Menggunakannya di Notebook selanjutnya\n","atlantic_storms.to_csv(\"atlantic_storms.csv\", encoding='utf-8')"]},{"cell_type":"markdown","metadata":{"id":"VJYi2fnBVBtN"},"source":["## Pendekatan Alternatif : \n","\n","Di atas kita telah melihat aliran di mana kita mendekati masalah, kita juga dapat memecahkan masalah yang sama menggunakan pendekatan alternatif: \n","\n","![alt_text](images/alt.png)\n"," \n","Tapi, pendekatan selanjutnya tidak disarankan dan alasan di balik hal yang sama terletak pada data yang kami kerjakan:\n","\n","Mari kita ambil output dari sel yang berisi nama-nama gambar: \n","\n","```\n","['20040729.0645.goes-12.ir.x.99LINVEST.25kts-1009mb-250N-710W.jpg',\n"," '20040729.0702.goes-12.ir.x.99LINVEST.25kts-1009mb-250N-710W.jpg',\n"," '20040729.0715.goes-12.ir.x.99LINVEST.25kts-1009mb-250N-710W.jpg',\n"," '20040729.0732.goes-12.ir.x.99LINVEST.25kts-1009mb-250N-710W.jpg',\n"," '20040729.0745.goes-12.ir.x.99LINVEST.25kts-1009mb-250N-710W.jpg']\n"," ```\n","\n","Kita dapat melihat waktu gambar di atas, diambil kira-kira setiap 15 menit.\n","\n","Mari kita lihat interval waktu himpunan data text."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCPYSrN4VBtO"},"outputs":[],"source":["atlantic_storms.tail()['date']"]},{"cell_type":"markdown","metadata":{"id":"_yhQ7L3NVBtO"},"source":["Di sini, kami melihat data text yang akan diambil sampelnya setiap enam jam sekali karena itu kami akan menggunakan teknik interpolasi untuk menemukan kecepatan pada saat tertentu. \n","\n","Sekarang menentukan kecepatan setiap saat dengan data interpolasi ini akan menyimpang dari nilai kebenaran, tetapi kita tahu bahwa suatu kelas memiliki rentang kecepatan sehingga probabilitas bahwa kelas interpolasi kita benar lebih nyata dibandingkan dengan yang pertama.\n","\n","## Licensing\n","This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0)."]},{"cell_type":"markdown","metadata":{"id":"Ld5bf-VEVBtP"},"source":["[Previous Notebook](The_Problem_Statement.ipynb)\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","[1](The_Problem_Statement.ipynb)\n","[2]\n","[3](Manipulation_of_Image_Data_and_Category_Determination_using_Text_Data.ipynb)\n","[4](Countering_Data_Imbalance.ipynb)\n","[5](Competition.ipynb)\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","[Next Notebook](Manipulation_of_Image_Data_and_Category_Determination_using_Text_Data.ipynb)\n","\n","\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&ensp;\n","[Home Page](../Start_Here.ipynb)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}