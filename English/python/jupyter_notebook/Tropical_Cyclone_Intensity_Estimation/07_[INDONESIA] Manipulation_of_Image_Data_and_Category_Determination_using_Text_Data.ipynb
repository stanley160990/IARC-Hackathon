{"cells":[{"cell_type":"markdown","metadata":{"id":"leUFgc5OSSTh"},"source":[]},{"cell_type":"markdown","metadata":{"id":"iFBa8WgWSSTk"},"source":["# Estimasi Tropical Cyclone Intensity menggunakan Deep  Convolutional Neural Network - bagian 2 \n","\n","**isi pada notebook:**\n","\n","- [Memahami Persyaratan Model](#Memahami-Persyaratan-Model)\n","    - [Menjelajahi Opsi Pengubahan Ukuran](#Menjelajahi-berbagai-jenis-opsi-pengubahan-ukuran)\n","    - [Memilih Patch Acak](#Langkah-2-:-Memilih-Patch-Acak-dari-Gambar)\n","- [Menganotasi Kumpulan Data ](#Menganotasi-Kumpulan-Data) \n","- [Penggabungan](#Penggabungan-:)\n","    - [Mempersiapkan Dataset](#Mempersiapkan-Dataset)\n","    - [Mendefinisikan Model](#Mendefinisikan-Model)\n","    - [Menyusun dan Melatih Model](#Menyusun-dan-Melatih-Model)\n","    - [Visualisasi](#Visualisasi)\n","\n","**Pada akhir Notebook ini Anda akan:**\n","\n","- Memahami Persyaratan Model.\n","- Anotasi Dataset.\n","- Latih Model Anda."]},{"cell_type":"markdown","metadata":{"id":"OJHoxW4ySSTl"},"source":["## Memahami Persyaratan Model\n","\n","### Kita telah melihat model yang akan diproses pada gambar kita\n","\n","- Model yang dijelaskan di Paper \n","![alt text](images/model.png)\n","\n","Kita dapat melihat bahwa gambar harus dalam bentuk ( 232, 232, 3) untuk dimasukkan ke dalam model kita.\n","\n","Jadi, kita akan melakukan langkah-langkah berikut sebelum memasukkan gambar ke dalam model kita.\n","\n","- Langkah 1 : Ubah Ukuran Gambar dari ( 1024, 1024 ,3) menjadi ( 256 , 256 ,3 ) \n","- Langkah 2 : Pilih acak ( 232 , 232 , 3 ) dari patch ( 256 , 256 , 3 ) dan masukkan ke dalam model kita.\n","\n","**Pendekatan Alternatif** : Kita dapat memodifikasi bentuk input model menjadi ( 256 x 256 x 3 ) dan melatihnya pada gambar yang diskalakan, tetapi kita mengambil tambalan acak ( 232 x 232 x 3 ) sehingga model kita tidak berharap siklon berada di tengah dan belajar memahami pemetaan bahkan dengan siklon di sisi gambar.\n","\n","### Langkah 1 :\n","Sekarang mari mulai dengan Langkah 1 dan pahami semua metode pengubahan ukuran yang tersedia untuk melakukannya."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wx_TyU5uSSTm"},"outputs":[],"source":["import cv2\n","#Membaca Gambar dengan menggunakan cv2.imread()\n","img = cv2.imread('images/image_shape.jpg',1)\n","#Mengubah Ruang Warna\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","# Cetak Bentuk Gambar\n","img.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKRpvjYRSSTn"},"outputs":[],"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","#Plot Gambar\n","plt.imshow(img)"]},{"cell_type":"markdown","metadata":{"id":"KgHQXnZeSSTn"},"source":["## Menjelajahi berbagai jenis opsi pengubahan ukuran \n","\n","Gambar dapat diubah ukurannya dengan berbagai cara. Beberapa metode adalah sebagai berikut (seperti yang dinyatakan dalam dokumentasi OpenCV) : \n","\n","<h3>Penskalaan</h3>\n","<p>Penskalaan hanyalah mengubah ukuran gambar. OpenCV dilengkapi dengan fungsi <b>cv2.resize()</a></b> untuk tujuan ini. Ukuran gambar dapat ditentukan secara manual, atau Anda dapat menentukan faktor penskalaan. Metode interpolasi yang berbeda digunakan. Metode interpolasi yang lebih disukai adalah <b>cv2.INTER_AREA</b> untuk penyusutan dan <b>cv2.INTER_CUBIC</b> (lambat) &amp; <b>cv2.INTER_LINEAR</b> untuk memperbesar. Secara default, metode interpolasi yang digunakan adalah <b>cv2.INTER_LINEAR</b> untuk semua tujuan pengubahan ukuran.\n","\n","* cv2.INTER_AREA    ( Lebih digunakan untuk Menyusut ) \n","* cv2.INTER_CUBIC   ( Lebih digunakan untuk Zooming tetapi lambat )\n","* cv2.INTER_LINEAR  ( Lebih digunakan untuk Zooming dan opsi default )\n"]},{"cell_type":"markdown","metadata":{"id":"rR1gFUZ6SSTo"},"source":["### Langkah 2 : Memilih Patch Acak dari Gambar\n","\n","Kita akan menggunakan fungsi `np.random.randint()` dari toolbox Numpy untuk menghasilkan angka acak. Parameter fungsi ini adalah batas atas dan ukuran larik Keluaran seperti yang disebutkan dalam [Numpy Documentation](https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html)"]},{"cell_type":"markdown","metadata":{"id":"J2gkm7abSSTo"},"source":["## Wrapping things up (Penggabungan)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5gI1AOqnSSTp"},"outputs":[],"source":["#Import numpy untuk Menghasilkan Angka Acak\n","import numpy as np\n","#Membuat nomor acak(random) mulai dari [0,0] sampai [23,23] dan mendefinisikan titik awal sampai titik akhir \n","start_pt= np.random.randint(24,size=2)\n","end_pt = start_pt + [232,232]\n","# Menskalakan gambar dan mengambil patch acak dari gambar tersebut\n","img  = cv2.resize(img,(256,256))\n","rand = img[start_pt[0]:end_pt[0],start_pt[1]:end_pt[1]]\n","plt.imshow(rand)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_FOaiEqSSTp"},"outputs":[],"source":["rand.shape"]},{"cell_type":"markdown","metadata":{"id":"s_jigORbSSTq"},"source":["Output Dari gambar akhir diperoleh sebagai (232, 232, 3)"]},{"cell_type":"markdown","metadata":{"id":"5xfGWOm-SSTr"},"source":["# Menganotasi Kumpulan Data \n","\n","Mari kita mulai dengan mengambil contoh Badai Katrina dari tahun 2005 dan menskalakannya untuk semua Topan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dk7Jb-pXSSTr"},"outputs":[],"source":["import pandas as pd\n","# Baca CSV yang kita simpan sebelumnya\n","df = pd.read_csv('atlantic_storms.csv')\n","# Buat Mask untuk Menyaring Topan Katrina kami (2005)\n","mask = (df['date'] > '2005-01-01') & (df['date'] <= '2006-01-01') & ( df['name'] == 'KATRINA')\n","# Terapkan Mask ke DataFrame Asli dan Ekstrak Dataframe Baru\n","new_df = df.loc[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLeF2yxkSSTr"},"outputs":[],"source":["new_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JaYgLnV3SSTr"},"outputs":[],"source":["#Mendapatkan daftar Gambar dari Kumpulan Data Kita untuk Katrina\n","import os\n","e = os.listdir('Dataset/tcdat/tc05/ATL/12L.KATRINA/ir/geo/1km')\n","e.sort()\n","#Tampilkan lima gambar pertama\n","e[:5]"]},{"cell_type":"markdown","metadata":{"id":"ms8-euNWSSTs"},"source":["#### Dapat kita amati, gambar diambil setiap 30 menit sekali, tetapi data teks tersedia setiap 6 jam sekali. Jadi kita akan menginterpolasi data teks agar sesuai dengan kurva"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDLe2nhDSSTs"},"outputs":[],"source":["#Dapatkan daftar Tanggal dan Kecepatan dari Dataframe Baru\n","date_list = new_df['date'].tolist()\n","velocity_list = new_df['maximum_sustained_wind_knots'].tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6aT4h4LtSSTs"},"outputs":[],"source":["print(date_list[:5])\n","type(date_list[0])"]},{"cell_type":"markdown","metadata":{"id":"Ed89Awv_SSTs"},"source":["Tanggal dalam Format STR yang akan kita konversi sekarang ke format datetime untuk digunakan."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uM8pOwvESSTs"},"outputs":[],"source":["from datetime import datetime\n","#Dapatkan dan Konversikan ke format Datetime untuk Waktu Rekaman Data Teks Pertama Terakhir.\n","first = (datetime.strptime(date_list[0], \"%Y-%m-%d %H:%M:%S\"))\n","last = (datetime.strptime(date_list[-1], \"%Y-%m-%d %H:%M:%S\"))\n","print(first)\n","type(first)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZE6GcRg9SSTt"},"outputs":[],"source":["#Mengubah daftar dari Konversi semuanya menjadi detik dari gambar pertama untuk menginterpolasi data\n","for i in range(len(date_list)):\n","    date_list[i]=( (datetime.strptime(date_list[i], \"%Y-%m-%d %H:%M:%S\")) - first ).total_seconds()\n","    print(date_list[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IxE4woFrSSTt"},"outputs":[],"source":["# Interpolasi menggunakan Fungsi Perpustakaan Scipy\n","from scipy import interpolate\n","func = interpolate.splrep(date_list,velocity_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7SkkW8ncSSTt"},"outputs":[],"source":["#Mendapatkan Daftar Gambar Katrina\n","import os\n","e = os.listdir('Dataset/tcdat/tc05/ATL/12L.KATRINA/ir/geo/1km')\n","#Urutkan gambar berdasarkan waktu\n","e.sort()\n","x=[]\n","y=[]\n","for m in e :\n","    try :\n","        #Lepaskan Data Waktu dari gambar dan ubah menjadi tipe waktu-waktu.\n","        time_img=(datetime.strptime(m[:13], \"%Y%m%d.%H%M\"))\n","        #Jika Gambar diambil antara data teks yang tersedia\n","        if(time_img>=first and time_img <= last):\n","            #Dapatkan Nilai Interpolasi untuk waktu itu dan Simpan\n","            value = int(interpolate.splev((time_img-first).total_seconds(),func))\n","            x.append((time_img-first).total_seconds())\n","            y.append(value)\n","    except :\n","       pass   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X_k3UN9DSSTt"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","#Plot Semua Poin Data Tersimpan\n","f = plt.figure(figsize=(24,10))\n","ax = f.add_subplot(121)\n","ax2 = f.add_subplot(122)\n","ax.title.set_text('Datapoints frm csv file')\n","ax2.title.set_text('Interpolated from CSV file to images')\n","ax.plot(date_list,velocity_list,'-o')\n","ax2.plot(x,y)"]},{"cell_type":"markdown","metadata":{"id":"w5GhIqBCSSTt"},"source":["### Sekarang kita telah menginterpolasi dan menemukan kecepatan yang relevan untuk semua gambar di antara kerangka waktu teks yang direkam. Sekarang mari kita gunakan untuk melatih Model kita."]},{"cell_type":"markdown","metadata":{"id":"CQORBnpRSSTu"},"source":["# Penggabungan :"]},{"cell_type":"markdown","metadata":{"id":"F3P15KVRSSTu"},"source":["### Mempersiapkan Dataset\n","\n","#####  Semua modul di atas digabungkan menjadi satu dan menjadikannya satu fungsi untuk memuat data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCyACX1VSSTv"},"outputs":[],"source":["import sys\n","sys.path.append('/workspace/python/source_code')\n","# Import Fungsi Utlility\n","from utils import * \n","# Muat kumpulan data\n","filenames,labels = load_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZGkSP5jwSSTw"},"outputs":[],"source":["val_filenames , val_labels = make_test_set(filenames,labels,val=0.1)"]},{"cell_type":"markdown","metadata":{"id":"fl0OcK09SSTw"},"source":["# Memahami Dataset :\n","\n","Kita bisa melihat baris berikut dari Output: \n","\n","`[344, 344, 344, 344, 344, 344, 344, 344]` and `{2: 7936, 3: 5339, 1: 3803, 4: 2934, 5: 2336, 6: 2178, 7: 204, 0: 100}`\n","\n","Ini adalah distribusi set validasi dan set pelatihan kita disetiap kelas-kelasnya.\n","\n","Untuk set validasi kita menggunakan set *Stratified Validation* sehingga set validasi kita hampir mewakili seluruh kelas.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SGsziUdRSSTw"},"outputs":[],"source":["#Membuat train test set\n","test = 0.2\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(filenames, labels, test_size=test, random_state=1)"]},{"cell_type":"markdown","metadata":{"id":"l8cPSA_sSSTx"},"source":["# One-Hot Encoding \n","\n","`y_train` adalah daftar yang berisi data dari 0-7 seperti [ 2,4,5,....] tetapi Model kita Membutuhkan Input Array untuk Setiap Output sebagai vektor 1D :\n","\n","2 --- > [ 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0] \n","\n","4 --- > [ 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0] \n","\n","\n","Ini dikodekan seperti itu karena menjaga nilai-nilai lain 0 diperlukan untuk model untuk menemukan Model Rugi dan menggunakan backpropagation untuk membuatnya mempelajari _Weight Matrix_.\n","\n","Gambar yang diberikan di bawah ini adalah contoh One-Hot Encoding:\n","\n","![alt text](images/one_hot.jfif)\n","\n","Sumber: [What is One Hot Encoding and How to Do It](https://medium.com/@michaeldelsole/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTGxKsFJSSTx"},"outputs":[],"source":["import tensorflow as tf\n","y_train = tf.one_hot(y_train,depth=8)\n","y_test = tf.one_hot(y_test,depth=8)\n","val_labels = tf.one_hot(val_labels,depth=8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"brPabE8ZSSTx"},"outputs":[],"source":["train,test,val = make_dataset((x_train,y_train,128),(x_test,y_test,32),(val_filenames,val_labels,32))"]},{"cell_type":"markdown","metadata":{"id":"MzlsOUrBSSTx"},"source":["### Mendefinisikan Model\n","\n","![alt_text](images/model.png)\n","\n","Kita akan Mengimplementasikan model ini di Keras menggunakan kode berikut"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYRr-ZrKSSTy"},"outputs":[],"source":["import numpy as np\n","import os\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n","tf.random.set_seed(1337)\n","\n","import tensorflow.keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten ,Dropout, MaxPooling2D\n","from tensorflow.keras import backend as K \n","\n","#Setel Ulang Grafik dan Buat model Berurutan\n","K.clear_session()\n","model = Sequential()\n","#Lapisan Konvolusi\n","\n","model.add(Conv2D(64, kernel_size=10,strides=3, activation='relu', input_shape=(232,232,3)))\n","model.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n","model.add(Conv2D(256, kernel_size=5,strides=1,activation='relu'))\n","model.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n","model.add(Conv2D(288, kernel_size=3,strides=1,padding='same',activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2),strides=1))\n","model.add(Conv2D(272, kernel_size=3,strides=1,padding='same',activation='relu'))\n","model.add(Conv2D(256, kernel_size=3,strides=1,activation='relu'))\n","model.add(MaxPooling2D(pool_size=(3, 3),strides=2))\n","model.add(Dropout(0.5))\n","model.add(Flatten())\n","\n","#Lapisan Linier\n","\n","model.add(Dense(3584,activation='relu'))\n","model.add(Dense(2048,activation='relu'))\n","model.add(Dense(8, activation='softmax'))\n","\n","#Ringkasan Model Cetak\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"_afOdC_5SSTy"},"source":["### Menyusun dan Melatih Model\n","\n","Kita akan menggunakan yang berikut ini: \n","\n","- Pengoptimal : SGD ( Stochastic Gradient Descent ) dengan parameter yang disebutkan dalam makalah penelitian.\n","    - Learning Rate : 0.001\n","    - Momentum : 0.9\n","- Loss Function : Categorical Cross Entropy (Digunakan dalam klasifikasi multi-kelas)\n","- Metrik : Kita akan menggunakan dua metrik untuk menentukan performa model kita \n","    - Akurasi : Jumlah Prediksi yang benar / Total jumlah Prediksi\n","    - Akurasi -2 Teratas : Akurasi 2 Teratas berarti bahwa salah satu dari model 2 jawaban probabilitas tertinggi Anda harus cocok dengan jawaban yang diharapkan."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fcOkGx-RSSTz"},"outputs":[],"source":["import functools\n","\n","# Sertakan Metrik Akurasi Top-2\n","top2_acc = functools.partial(tensorflow.keras.metrics.top_k_categorical_accuracy, k=2)\n","top2_acc.__name__ = 'top2_acc'\n","\n","# Tentukan Jumlah epochs\n","epochs = 4\n","\n","#Tapi Melatih model kita dari awal akan memakan waktu lama\n","#Jadi kita akan memuat model yang dilatih sebagian untuk mempercepat proses \n","model.load_weights(\"trained_16.h5\")\n","\n","#Pengoptimal\n","sgd = tensorflow.keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9)\n","\n","\n","#Kompilasi Model dengan Loss Function , Pengoptimal dan Metrik\n","model.compile(loss=tensorflow.keras.losses.categorical_crossentropy, \n","              optimizer=sgd,\n","              metrics=['accuracy',top2_acc])\n","\n","#Latih Modelnya\n","trained_model = model.fit(train,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=val)\n","\n","#Uji Model Terhadap Set Validasi\n","score = model.evaluate(test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"]},{"cell_type":"markdown","metadata":{"id":"zVh8y76USSTz"},"source":["### Visualisasi\n","\n","Sekarang mari kita memvisualisasikan bagaimana model kita bekerja selama proses pelatihan: "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOT-kaMGSST0"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","f = plt.figure(figsize=(15,5))\n","ax = f.add_subplot(121)\n","ax.plot(trained_model.history['accuracy'])\n","ax.plot(trained_model.history['val_accuracy'])\n","ax.set_title('Model Accuracy')\n","ax.set_ylabel('Accuracy')\n","ax.set_xlabel('Epoch')\n","ax.legend(['Train', 'Val'])\n","\n","ax2 = f.add_subplot(122)\n","ax2.plot(trained_model.history['loss'])\n","ax2.plot(trained_model.history['val_loss'])\n","ax2.set_title('Model Loss')\n","ax2.set_ylabel('Loss')\n","ax2.set_xlabel('Epoch')\n","ax2.legend(['Train', 'Val'],loc= 'upper left')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"I96oHbKZSST0"},"source":["## Confusion Matrix :\n","\n","Sebuah Confusion matrix adalah tabel yang sering digunakan untuk menggambarkan kinerja model klasifikasi (atau \"classifier\") pada satu set data uji yang nilai sebenarnya diketahui.\n","\n","Di sini, baris menampilkan kelas yang diprediksi dan kolom adalah nilai kebenaran dari kelas. Dari sini kita dapat memperkirakan bagaimana model kita bekerja pada kelas yang berbeda yang pada gilirannya akan membantu kita menentukan bagaimana data kita harus dimasukkan ke dalam model kita.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"u09_7CIuSST0"},"outputs":[],"source":["import seaborn as sn\n","from sklearn.metrics import confusion_matrix\n","import pandas as pd\n","\n","#Merencanakan sebuah heatmap menggunakan confusion matrix\n","pred = model.predict(val)\n","p = np.argmax(pred, axis=1)\n","y_valid = np.argmax(val_labels, axis=1, out=None)\n","results = confusion_matrix(y_valid, p) \n","classes=['NC','TD','TC','H1','H3','H3','H4','H5']\n","df_cm = pd.DataFrame(results, index = [i for i in classes], columns = [i for i in classes])\n","plt.figure(figsize = (15,15))\n","\n","sn.heatmap(df_cm, annot=True, cmap=\"Blues\")"]},{"cell_type":"markdown","metadata":{"id":"JMxupWdxSST0"},"source":["### Selamat menjalankan model pertama Anda. Sekarang Di notebook berikutnya, mari kita coba memahami kekurangan model ini dan membuatnya lebih baik:\n","\n","\n","Kita dapat melihat bahwa akurasi validasi lebih rendah daripada akurasi pelatihan. Ini karena modelnya tidak diregulasi dengan benar dan kemungkinan alasannya adalah: \n","\n","**Poin data tidak cukup/ kelas tidak seimbang**\n","\n","Dengan menggunakan teknik yang berbeda, kita akan mengatur dan menormalkan model di notebook yang akan datang.\n","\n","## Penting:\n","<mark>Matikan kernel sebelum mengklik \"Notebook Berikutnya\" untuk mengosongkan memori GPU.</mark>\n","\n","## Lisensi:\n","Materi ini dirilis oleh OpenACC-Standard.org, bekerja sama dengan NVIDIA Corporation, di bawah Creative Commons Attribution 4.0 International (CC BY 4.0)."]},{"cell_type":"markdown","metadata":{"id":"tFVtb0paSST1"},"source":["[Previous Notebook](Approach_to_the_Problem_&_Inspecting_and_Cleaning_the_Required_Data.ipynb)\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","[1](The_Problem_Statement.ipynb)\n","[2](Approach_to_the_Problem_&_Inspecting_and_Cleaning_the_Required_Data.ipynb)\n","[3]\n","[4](Countering_Data_Imbalance.ipynb)\n","[5](Competition.ipynb)\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","[Next Notebook](Countering_Data_Imbalance.ipynb)\n","\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&emsp;&emsp;&emsp;\n","&emsp;&emsp;&ensp;\n","[Home Page](../Start_Here.ipynb)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}